{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd90fd30ef8f104",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T20:49:37.296174Z",
     "start_time": "2025-06-18T20:49:33.873802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/Vault/01 Development/University/p2p-credit-risk/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/thomas/Vault/01 Development/University/p2p-credit-risk/.venv/lib/python3.12/site-packages/art/estimators/certification/__init__.py:30: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f88fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_dir = 'ml/StandardScalerOneHotEncoder'\n",
    "X_train = pd.read_csv(os.path.join(data_dir, 'X_train.csv')).values\n",
    "y_train = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))['is_default'].values\n",
    "X_val   = pd.read_csv(os.path.join(data_dir, 'X_val.csv')).values\n",
    "y_val   = pd.read_csv(os.path.join(data_dir, 'y_val.csv'))['is_default'].values\n",
    "X_test  = pd.read_csv(os.path.join(data_dir, 'X_test.csv')).values\n",
    "y_test  = pd.read_csv(os.path.join(data_dir, 'y_test.csv'))['is_default'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ffe95f",
   "metadata": {},
   "source": [
    "### Model Creation Function\n",
    "\n",
    "-   **Architecture**: A `Sequential` model, which is a linear stack of layers.\n",
    "    -   It contains two hidden `Dense` (fully-connected) layers with 128 and 64 units respectively.\n",
    "    -   Each hidden layer uses the **`relu`** (Rectified Linear Unit) activation function. ReLU is chosen for its computational efficiency and its effectiveness in mitigating the vanishing gradient problem in deeper networks.\n",
    "\n",
    "-   **Regularization**: `Dropout` is used as a regularization technique to prevent overfitting.\n",
    "    -   `Dropout(0.3)` randomly sets 30% of the input units to 0 at each update during training. This prevents neurons from co-adapting too much and forces the model to learn more robust features.\n",
    "\n",
    "-   **Output Layer**: The final layer is configured for classification.\n",
    "    -   It is a `Dense` layer with 2 units, corresponding to the two output classes (defaulted vs not defaulted)\n",
    "    -   It uses the **`softmax`** activation function, which converts the raw output into a probability distribution. The output vector's components sum to 1, representing the model's predicted probability for each class.\n",
    "\n",
    "-   **Compiler**: This step configures the model's learning process.\n",
    "    -   **Optimizer (`adam`)**: The model uses the Adam (Adaptive Moment Estimation) optimizer. It's an efficient stochastic gradient descent algorithm that computes adaptive learning rates for each parameter by storing an exponentially decaying average of past squared gradients (like RMSprop) and past gradients (like momentum). It is a robust and widely used default optimizer.\n",
    "    -   **Loss Function (`sparse_categorical_crossentropy`)**: The loss function measures the divergence between the true and predicted probability distributions. The `sparse` version of categorical crossentropy is used here because the ground-truth labels are provided as integers (e.g., `0`, `1`), not as one-hot encoded vectors.\n",
    "   \n",
    "The Dense layer and Dropout rates are common starting points, not chosen through experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db602e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d26336",
   "metadata": {},
   "source": [
    "### Training Configuration Parameters\n",
    "\n",
    "-   **`epochs=50`**: An **epoch** is one complete forward and backward pass of the entire training dataset. Setting this to 50 establishes the *maximum* number of training cycles. In practice, the training will likely end sooner due to the `EarlyStopping` callback.\n",
    "\n",
    "-   **`batch_size=256`**: The training data is not processed all at once. Instead, it is broken down into smaller subsets called **batches**. The model's internal weights are updated after processing each batch. This method, mini-batch gradient descent, is more memory-efficient and often leads to faster convergence and better generalization than processing the entire dataset in one go. A batch size of 256 is a common choice, as powers of two can optimize memory allocation on GPUs.\n",
    "\n",
    "-   **`callbacks=[tf.keras.callbacks.EarlyStopping(...)]`**: **Callbacks** are objects that can perform actions at various stages of training, such as at the end of an epoch. They are used here to implement a crucial control mechanism.\n",
    "    -   **`EarlyStopping`**: This callback is a form of regularization that prevents **overfitting** by halting the training process once the model's performance stops improving on a validation set.\n",
    "        -   `monitor='val_loss'`: The specific metric being monitored is the loss calculated on the validation data (`X_val`, `y_val`). This is the most important indicator of how well the model generalizes to unseen data. If this value stops decreasing, the model is no longer learning useful patterns.\n",
    "        -   `patience=5`: This parameter defines the number of epochs to wait for an improvement before stopping. A `patience` of 5 allows the training to continue for 5 epochs even if `val_loss` is not improving, which helps to avoid stopping prematurely due to random fluctuations in the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a86f1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x324e81ee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Baseline Model\n",
    "input_dim = X_train.shape[1]\n",
    "baseline_model = create_model(input_dim)\n",
    "baseline_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdac8da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on clean data: 0.6663\n",
      "Accuracy on clean data: 0.6145\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Baseline Model on CLEAN Data\n",
    "baseline_preds_clean_probs = baseline_model.predict(X_test, verbose=0)[:, 1]\n",
    "baseline_preds_clean_labels = (baseline_preds_clean_probs >= 0.5).astype(int)\n",
    "\n",
    "auc_baseline_clean = roc_auc_score(y_test, baseline_preds_clean_probs)\n",
    "acc_baseline_clean = accuracy_score(y_test, baseline_preds_clean_labels)\n",
    "\n",
    "print(f\"AUC on clean data: {auc_baseline_clean:.4f}\")\n",
    "print(f\"Accuracy on clean data: {acc_baseline_clean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed58856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial examples created.\n"
     ]
    }
   ],
   "source": [
    "# Create the Adversarial Attack\n",
    "\n",
    "# Wrap the Keras model in an ART classifier - The clip_values are important to bound the perturbations\n",
    "classifier_art = TensorFlowV2Classifier(\n",
    "    model=baseline_model, \n",
    "    nb_classes=2, \n",
    "    input_shape=(X_train.shape[1],), \n",
    "    loss_object=tf.keras.losses.BinaryCrossentropy(),\n",
    "    clip_values=(np.min(X_train), np.max(X_train))\n",
    ")\n",
    "\n",
    "# Create the attack instance (Fast Gradient Sign Method)\n",
    "attack = FastGradientMethod(estimator=classifier_art, eps=0.1)\n",
    "\n",
    "# Generate adversarial examples from the original test set\n",
    "x_test_adv = attack.generate(x=X_test)\n",
    "print(\"Adversarial examples created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103663ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Baseline Model on ADVERSARIAL Test Data ---\n",
      "AUC on adversarial data: 0.4771\n",
      "Accuracy on adversarial data: 0.4380\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Baseline Model on ADVERSARIAL Data\n",
    "print(\"\\n--- Evaluating Baseline Model on ADVERSARIAL Test Data ---\")\n",
    "\n",
    "baseline_preds_adv_probs = classifier_art.predict(x_test_adv, verbose=0)[:, 1]\n",
    "baseline_preds_adv_labels = (baseline_preds_adv_probs >= 0.5).astype(int)\n",
    "\n",
    "auc_baseline_adv = roc_auc_score(y_test, baseline_preds_adv_probs)\n",
    "acc_baseline_adv = accuracy_score(y_test, baseline_preds_adv_labels)\n",
    "\n",
    "print(f\"AUC on adversarial data: {auc_baseline_adv:.4f}\")\n",
    "print(f\"Accuracy on adversarial data: {acc_baseline_adv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093d3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing QUICK Adversarial Training (fewer epochs) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompute adv samples: 100%|██████████| 1/1 [00:06<00:00,  6.84s/it]\n",
      "Adversarial training epochs:   0%|          | 0/5 [00:00<?, ?it/s]2025-06-21 15:05:57.481972: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-06-21 15:05:57.572962: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowV2Classifier.fit.<locals>.train_step at 0x3383ddd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowV2Classifier.fit.<locals>.train_step at 0x3383ddd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 15:05:57.768607: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-06-21 15:05:58.109846: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-06-21 15:05:58.791287: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-06-21 15:06:00.339769: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-06-21 15:06:03.371018: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-06-21 15:06:09.502177: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-06-21 15:06:21.546701: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Adversarial training epochs:  20%|██        | 1/5 [00:33<02:13, 33.29s/it]2025-06-21 15:06:45.339861: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Adversarial training epochs:  40%|████      | 2/5 [01:06<01:40, 33.36s/it]2025-06-21 15:07:33.734630: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Adversarial training epochs: 100%|██████████| 5/5 [02:44<00:00, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick robust model training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform Adversarial Training \n",
    "print(\"\\n--- Performing QUICK Adversarial Training (fewer epochs) ---\")\n",
    "\n",
    "robust_model_quick = create_model(input_dim)\n",
    "\n",
    "robust_classifier_quick = TensorFlowV2Classifier(\n",
    "    model=robust_model_quick,\n",
    "    nb_classes=2,\n",
    "    input_shape=(X_train.shape[1],),\n",
    "    loss_object=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    clip_values=(np.min(X_train), np.max(X_train)),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    ")\n",
    "\n",
    "trainer_quick = AdversarialTrainer(classifier=robust_classifier_quick, attacks=attack, ratio=0.5)\n",
    "\n",
    "# Run for only 5 epochs instead of 50 for a quick test.\n",
    "trainer_quick.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    nb_epochs=5,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "print(\"Quick robust model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17acfa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped\n"
     ]
    }
   ],
   "source": [
    "# # Perform Adversarial Training for Defense\n",
    "\n",
    "# #  Create a new, fresh model instance for robust training\n",
    "# robust_model = create_model(input_dim)\n",
    "\n",
    "#  Wrap it in the TensorFlowV2Classifier\n",
    "# robust_classifier = TensorFlowV2Classifier(\n",
    "#     model=robust_model,\n",
    "#     nb_classes=2,\n",
    "#     input_shape=(X_train.shape[1],),\n",
    "#     loss_object=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#     clip_values=(np.min(X_train), np.max(X_train)),\n",
    "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# )\n",
    "\n",
    "#  Create an AdversarialTrainer instance\n",
    "# trainer = AdversarialTrainer(classifier=robust_classifier, attacks=attack, ratio=0.5)\n",
    "\n",
    "#  Train the robust model using the trainer's fit method\n",
    "# trainer.fit(\n",
    "#     x=X_train,\n",
    "#     y=y_train,\n",
    "#     nb_epochs=50,\n",
    "#     batch_size=256\n",
    "# )\n",
    "\n",
    "# print(\"Robust model training complete.\")\n",
    "print('Skipped')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f3a1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on CLEAN data...\n",
      "Quick Robust Model - AUC on CLEAN data: 0.6635\n",
      "Quick Robust Model - Accuracy on CLEAN data: 0.6105\n",
      "\n",
      "Evaluating on ADVERSARIAL data...\n",
      "Quick Robust Model - AUC on ADVERSARIAL data: 0.6100\n",
      "Quick Robust Model - Accuracy on ADVERSARIAL data: 0.6145\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the QUICKLY-Trained Robust Model\n",
    "\n",
    "# Evaluate on the original, CLEAN test data\n",
    "print(\"Evaluating on CLEAN data...\")\n",
    "robust_preds_clean_probs = robust_classifier_quick.predict(X_test, verbose=0)[:, 1]\n",
    "robust_preds_clean_labels = (robust_preds_clean_probs >= 0.5).astype(int)\n",
    "auc_robust_clean_quick = roc_auc_score(y_test, robust_preds_clean_probs)\n",
    "acc_robust_clean_quick = accuracy_score(y_test, robust_preds_clean_labels)\n",
    "print(f\"Quick Robust Model - AUC on CLEAN data: {auc_robust_clean_quick:.4f}\")\n",
    "print(f\"Quick Robust Model - Accuracy on CLEAN data: {acc_robust_clean_quick:.4f}\")\n",
    "\n",
    "# Evaluate on the ADVERSARIAL test data (created earlier)\n",
    "print(\"\\nEvaluating on ADVERSARIAL data...\")\n",
    "robust_preds_adv_probs = robust_classifier_quick.predict(x_test_adv, verbose=0)[:, 1]\n",
    "robust_preds_adv_labels = (robust_preds_adv_probs >= 0.5).astype(int)\n",
    "auc_robust_adv_quick = roc_auc_score(y_test, robust_preds_adv_probs)\n",
    "acc_robust_adv_quick = accuracy_score(y_test, robust_preds_adv_labels)\n",
    "print(f\"Quick Robust Model - AUC on ADVERSARIAL data: {auc_robust_adv_quick:.4f}\")\n",
    "print(f\"Quick Robust Model - Accuracy on ADVERSARIAL data: {acc_robust_adv_quick:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9b5624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Model Type    Test Data     AUC  Accuracy\n",
      "0        Baseline        Clean  0.6663    0.6145\n",
      "1        Baseline  Adversarial  0.4771    0.4380\n",
      "2  Robust (Quick)        Clean  0.6635    0.6105\n",
      "3  Robust (Quick)  Adversarial  0.6100    0.6145\n"
     ]
    }
   ],
   "source": [
    "# Summary of All Results\n",
    "summary_data = {\n",
    "    \"Model Type\": [\"Baseline\", \"Baseline\", \"Robust (Quick)\", \"Robust (Quick)\"],\n",
    "    \"Test Data\": [\"Clean\", \"Adversarial\", \"Clean\", \"Adversarial\"],\n",
    "    \"AUC\": [auc_baseline_clean, auc_baseline_adv, auc_robust_clean_quick, auc_robust_adv_quick],\n",
    "    \"Accuracy\": [acc_baseline_clean, acc_baseline_adv, acc_robust_clean_quick, acc_robust_adv_quick]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa2f512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model - Clean Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Default       0.68      0.31      0.43      8990\n",
      "     Default       0.60      0.87      0.71     10523\n",
      "\n",
      "    accuracy                           0.61     19513\n",
      "   macro avg       0.64      0.59      0.57     19513\n",
      "weighted avg       0.63      0.61      0.58     19513\n",
      "\n",
      "\n",
      "Baseline Model - Adversarial Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Default       0.43      0.64      0.51      8990\n",
      "     Default       0.46      0.27      0.34     10523\n",
      "\n",
      "    accuracy                           0.44     19513\n",
      "   macro avg       0.44      0.45      0.42     19513\n",
      "weighted avg       0.45      0.44      0.42     19513\n",
      "\n",
      "\n",
      "Robust (Quick) Model - Clean Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Default       0.66      0.32      0.43      8990\n",
      "     Default       0.60      0.86      0.70     10523\n",
      "\n",
      "    accuracy                           0.61     19513\n",
      "   macro avg       0.63      0.59      0.57     19513\n",
      "weighted avg       0.62      0.61      0.58     19513\n",
      "\n",
      "\n",
      "Robust (Quick) Model - Adversarial Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Default       0.68      0.31      0.43      8990\n",
      "     Default       0.60      0.87      0.71     10523\n",
      "\n",
      "    accuracy                           0.61     19513\n",
      "   macro avg       0.64      0.59      0.57     19513\n",
      "weighted avg       0.63      0.61      0.58     19513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline on Clean\n",
    "print(\"\\nBaseline Model - Clean Test Data\")\n",
    "print(classification_report(y_test, baseline_preds_clean_labels, target_names=[\"Not Default\", \"Default\"]))\n",
    "\n",
    "# Baseline on Adversarial\n",
    "print(\"\\nBaseline Model - Adversarial Test Data\")\n",
    "print(classification_report(y_test, baseline_preds_adv_labels, target_names=[\"Not Default\", \"Default\"]))\n",
    "\n",
    "# Robust (Quick) on Clean\n",
    "print(\"\\nRobust (Quick) Model - Clean Test Data\")\n",
    "print(classification_report(y_test, robust_preds_clean_labels, target_names=[\"Not Default\", \"Default\"]))\n",
    "\n",
    "# Robust (Quick) on Adversarial\n",
    "print(\"\\nRobust (Quick) Model - Adversarial Test Data\")\n",
    "print(classification_report(y_test, robust_preds_adv_labels, target_names=[\"Not Default\", \"Default\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
